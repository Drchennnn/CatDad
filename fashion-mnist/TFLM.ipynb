{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892cb52b",
   "metadata": {},
   "source": [
    "# Fashion-MNIST Transfer Learning Project\n",
    "\n",
    "This project demonstrates the complete workflow of applying transfer learning using pre-trained deep learning models (MobileNetV2 and ResNet50) on the Fashion-MNIST dataset.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**Transfer Learning** is a machine learning technique that leverages models pre-trained on large datasets to solve new, related tasks. In this project, we utilize models pre-trained on ImageNet to classify Fashion-MNIST clothing images.\n",
    "\n",
    "**Key Advantages:**\n",
    "- Reduced training time\n",
    "- Requires less training data\n",
    "- Often achieves better performance\n",
    "- Lower computational resource requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad3d4b1",
   "metadata": {},
   "source": [
    "# Configuration Management and Environment Setup\n",
    "\n",
    "First, we establish all hyperparameters and configurations for our experiment. Centralized configuration management helps ensure reproducibility and facilitates parameter tuning.\n",
    "\n",
    "**This section covers:**\n",
    "- Import all necessary libraries\n",
    "- Define a Config class with all hyperparameters\n",
    "- Set random seeds for reproducibility\n",
    "- Configure device (CPU/GPU) settings\n",
    "- Create necessary directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f32abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import gzip\n",
    "import struct\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.cuda.amp import autocast, GradScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a091524",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration class containing all hyperparameters and settings\"\"\"\n",
    "    \n",
    "    # Random seeds for reproducibility\n",
    "    RANDOM_SEED = 42\n",
    "    \n",
    "    # Data paths\n",
    "    TRAIN_IMAGES_PATH = 'data/train-images-idx3-ubyte.gz'\n",
    "    TRAIN_LABELS_PATH = 'data/train-labels-idx1-ubyte.gz'\n",
    "    TEST_IMAGES_PATH = 'data/t10k-images-idx3-ubyte.gz'\n",
    "    TEST_LABELS_PATH = 'data/t10k-labels-idx1-ubyte.gz'\n",
    "    \n",
    "    # Model parameters\n",
    "    NUM_CLASSES = 10\n",
    "    INPUT_SIZE = 112  # Upsampled size (smaller than 224 for faster processing)\n",
    "    \n",
    "    # Training parameters\n",
    "    BATCH_SIZE = 32\n",
    "    LEARNING_RATE = 0.01\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    MAX_LR = 0.02\n",
    "    NUM_EPOCHS = 5\n",
    "    TRAIN_VAL_SPLIT = 0.8\n",
    "    ACCUMULATION_STEPS = 2\n",
    "    \n",
    "    # Early stopping\n",
    "    PATIENCE = 2\n",
    "    \n",
    "    # Output paths\n",
    "    MODELS_DIR = 'models'\n",
    "    RESULTS_DIR = 'results'\n",
    "    \n",
    "    # Device configuration\n",
    "    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Fashion-MNIST class names\n",
    "CLASS_NAMES = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Initialize random seeds and create directories\"\"\"\n",
    "    # Set random seeds for reproducibility\n",
    "    np.random.seed(Config.RANDOM_SEED)\n",
    "    torch.manual_seed(Config.RANDOM_SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(Config.RANDOM_SEED)\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(Config.MODELS_DIR, exist_ok=True)\n",
    "    os.makedirs(Config.RESULTS_DIR, exist_ok=True)\n",
    "    \n",
    "    print(f\"Using device: {Config.DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf0e56",
   "metadata": {},
   "source": [
    "#  Data Loading and Preprocessing Module\n",
    "\n",
    "This module handles Fashion-MNIST data loading, preprocessing, and augmentation. Since we're using pre-trained models, proper data preprocessing is crucial to match the input requirements of pre-trained models.\n",
    "\n",
    "**Key Components:**\n",
    "- **Data Format Conversion**: Adapt grayscale images to pre-trained model requirements\n",
    "- **Image Resizing**: Upsample 28×28 images to 112×112 for better compatibility\n",
    "- **Dataset Splitting**: Create training, validation, and test sets\n",
    "- **Batch Processing**: Handle large datasets efficiently to avoid memory issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef314df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTLoader:\n",
    "    \"\"\"Handle Fashion-MNIST data loading and preprocessing\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_mnist_data(images_path, labels_path):\n",
    "        \"\"\"\n",
    "        Load Fashion-MNIST data from compressed files\n",
    "        Args:\n",
    "            images_path (str): Path to images file\n",
    "            labels_path (str): Path to labels file\n",
    "        Returns:\n",
    "            tuple: (images, labels) as numpy arrays\n",
    "        \"\"\"\n",
    "        # Read images\n",
    "        with gzip.open(images_path, 'rb') as f:\n",
    "            magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "            images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "            images = images.reshape(num, rows, cols)\n",
    "        \n",
    "        # Read labels\n",
    "        with gzip.open(labels_path, 'rb') as f:\n",
    "            magic, num = struct.unpack('>II', f.read(8))\n",
    "            labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        \n",
    "        return images, labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_images(images):\n",
    "        \"\"\"\n",
    "        Preprocess images: resize and convert to tensors\n",
    "        Args:\n",
    "            images (np.array): Raw images\n",
    "        Returns:\n",
    "            torch.Tensor: Preprocessed images\n",
    "        \"\"\"\n",
    "        processed_images = []\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((Config.INPUT_SIZE, Config.INPUT_SIZE), \n",
    "                            interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        for img in images:\n",
    "            # Convert to PIL image\n",
    "            pil_img = Image.fromarray(img, mode='L')\n",
    "            # Apply transformations\n",
    "            tensor_img = transform(pil_img)\n",
    "            processed_images.append(tensor_img)\n",
    "        \n",
    "        return torch.stack(processed_images)\n",
    "    \n",
    "    @staticmethod\n",
    "    def batch_preprocess(images, batch_size=5000):\n",
    "        \"\"\"\n",
    "        Process images in batches to reduce memory usage\n",
    "        Args:\n",
    "            images (np.array): Raw images\n",
    "            batch_size (int): Batch size for processing\n",
    "        Returns:\n",
    "            torch.Tensor: All processed images\n",
    "        \"\"\"\n",
    "        all_processed = []\n",
    "        num_batches = len(images) // batch_size + (1 if len(images) % batch_size > 0 else 0)\n",
    "        \n",
    "        for i in tqdm(range(num_batches), desc=\"Preprocessing images\"):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, len(images))\n",
    "            batch_images = images[start_idx:end_idx]\n",
    "            processed_batch = FashionMNISTLoader.preprocess_images(batch_images)\n",
    "            all_processed.append(processed_batch)\n",
    "        \n",
    "        return torch.cat(all_processed)\n",
    "\n",
    "class DatasetManager:\n",
    "    \"\"\"Manage dataset creation and data loaders\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.test_loader = None\n",
    "    \n",
    "    def load_and_prepare_data(self):\n",
    "        \"\"\"Load and prepare all datasets\"\"\"\n",
    "        print(\"Loading Fashion-MNIST dataset...\")\n",
    "        \n",
    "        # Load training and test data\n",
    "        train_images, train_labels = FashionMNISTLoader.load_mnist_data(\n",
    "            Config.TRAIN_IMAGES_PATH, Config.TRAIN_LABELS_PATH)\n",
    "        test_images, test_labels = FashionMNISTLoader.load_mnist_data(\n",
    "            Config.TEST_IMAGES_PATH, Config.TEST_LABELS_PATH)\n",
    "        \n",
    "        print(f\"Train set: {train_images.shape} images, {train_labels.shape} labels\")\n",
    "        print(f\"Test set: {test_images.shape} images, {test_labels.shape} labels\")\n",
    "        \n",
    "        # Preprocess data\n",
    "        print(\"Preprocessing data...\")\n",
    "        X_train_tensor = FashionMNISTLoader.batch_preprocess(train_images)\n",
    "        X_test_tensor = FashionMNISTLoader.batch_preprocess(test_images)\n",
    "        y_train_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "        y_test_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
    "        \n",
    "        print(f\"Processed train images shape: {X_train_tensor.shape}\")\n",
    "        print(f\"Processed test images shape: {X_test_tensor.shape}\")\n",
    "        \n",
    "        return X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor\n",
    "    \n",
    "    def create_data_loaders(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Create data loaders for training, validation, and testing\"\"\"\n",
    "        # Create train dataset and split into train/validation\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        \n",
    "        # Split training data (80% train, 20% validation)\n",
    "        train_size = int(Config.TRAIN_VAL_SPLIT * len(train_dataset))\n",
    "        val_size = len(train_dataset) - train_size\n",
    "        train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "        \n",
    "        # Create test dataset\n",
    "        test_dataset = TensorDataset(X_test, y_test)\n",
    "        \n",
    "        print(f\"Train subset size: {len(train_subset)} samples\")\n",
    "        print(f\"Validation subset size: {len(val_subset)} samples\")\n",
    "        print(f\"Test set size: {len(test_dataset)} samples\")\n",
    "        \n",
    "        # Create data loaders\n",
    "        self.train_loader = DataLoader(\n",
    "            train_subset, batch_size=Config.BATCH_SIZE, shuffle=True, \n",
    "            num_workers=4, pin_memory=True)\n",
    "        \n",
    "        self.val_loader = DataLoader(\n",
    "            val_subset, batch_size=Config.BATCH_SIZE*2, shuffle=False, \n",
    "            num_workers=4, pin_memory=True)\n",
    "        \n",
    "        self.test_loader = DataLoader(\n",
    "            test_dataset, batch_size=Config.BATCH_SIZE*2, shuffle=False, \n",
    "            num_workers=4, pin_memory=True)\n",
    "        \n",
    "        return self.train_loader, self.val_loader, self.test_loader\n",
    "    \n",
    "    def visualize_samples(self, X_train, y_train):\n",
    "        \"\"\"Visualize some data samples\"\"\"\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for i in range(9):\n",
    "            plt.subplot(3, 3, i + 1)\n",
    "            # Convert tensor back to numpy for visualization\n",
    "            img = X_train[i].squeeze().numpy()\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.title(CLASS_NAMES[y_train[i]])\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{Config.RESULTS_DIR}/data_samples.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d361da8",
   "metadata": {},
   "source": [
    "# Transfer Learning Model Architecture\n",
    "\n",
    "This section defines our transfer learning models by modifying pre-trained architectures. We implement two popular CNN architectures: MobileNetV2 and ResNet50.\n",
    "\n",
    "**Model Modifications:**\n",
    "- **Input Layer Adaptation**: Modify first convolutional layer to accept single-channel (grayscale) input\n",
    "- **Layer Freezing Strategy**: Implement configurable layer freezing for feature extraction vs fine-tuning\n",
    "- **Output Layer Replacement**: Replace final classification layer to match our 10 Fashion-MNIST classes\n",
    "- **Weight Initialization**: Properly initialize modified layers using pre-trained weights\n",
    "\n",
    "**Two Training Strategies:**\n",
    "1. **Feature Extraction**: Freeze all pre-trained layers, only train the final classifier\n",
    "2. **Fine-tuning**: Unfreeze some top layers for domain-specific adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d02738",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetTransferLearning(nn.Module):\n",
    "    \"\"\"MobileNetV2 model adapted for transfer learning\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10, trainable_layers=0):\n",
    "        super(MobileNetTransferLearning, self).__init__()\n",
    "        \n",
    "        # Load pretrained MobileNetV2 model\n",
    "        self.model = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Modify first convolutional layer to accept single-channel input\n",
    "        self._modify_input_layer()\n",
    "        \n",
    "        # Freeze/unfreeze layers based on trainable_layers parameter\n",
    "        self._configure_trainable_layers(trainable_layers)\n",
    "        \n",
    "        # Modify classifier for new number of classes\n",
    "        self.model.classifier[1] = nn.Linear(\n",
    "            self.model.classifier[1].in_features, num_classes)\n",
    "    \n",
    "    def _modify_input_layer(self):\n",
    "        \"\"\"Modify first conv layer to accept grayscale input\"\"\"\n",
    "        original_conv = self.model.features[0][0]\n",
    "        self.model.features[0][0] = nn.Conv2d(\n",
    "            1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        \n",
    "        # Initialize weights by summing original RGB weights\n",
    "        with torch.no_grad():\n",
    "            self.model.features[0][0].weight[:, 0:1, :, :] = \\\n",
    "                original_conv.weight.sum(dim=1, keepdim=True)\n",
    "    \n",
    "    def _configure_trainable_layers(self, trainable_layers):\n",
    "        \"\"\"Configure which layers are trainable\"\"\"\n",
    "        total_params = len(list(self.model.parameters()))\n",
    "        \n",
    "        if trainable_layers > 0:\n",
    "            print(f\"MobileNetV2: Unfreezing last {trainable_layers} layers \"\n",
    "                  f\"for fine-tuning, total {total_params} layers\")\n",
    "        else:\n",
    "            print(f\"MobileNetV2: Freezing all pretrained layers, \"\n",
    "                  f\"training classifier only\")\n",
    "        \n",
    "        trainable_count = 0\n",
    "        for i, param in enumerate(self.model.parameters()):\n",
    "            if i < total_params - trainable_layers:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "                trainable_count += 1\n",
    "        \n",
    "        print(f\"Total {trainable_count} layers unfrozen for training\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class ResNet50TransferLearning(nn.Module):\n",
    "    \"\"\"ResNet50 model adapted for transfer learning\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10, trainable_layers=0):\n",
    "        super(ResNet50TransferLearning, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet50 model\n",
    "        self.model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Modify first convolutional layer to accept single-channel input\n",
    "        self._modify_input_layer()\n",
    "        \n",
    "        # Freeze/unfreeze layers based on trainable_layers parameter\n",
    "        self._configure_trainable_layers(trainable_layers)\n",
    "        \n",
    "        # Modify final layer for new number of classes\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "    \n",
    "    def _modify_input_layer(self):\n",
    "        \"\"\"Modify first conv layer to accept grayscale input\"\"\"\n",
    "        original_conv = self.model.conv1\n",
    "        self.model.conv1 = nn.Conv2d(\n",
    "            1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # Initialize weights by summing original RGB weights\n",
    "        with torch.no_grad():\n",
    "            self.model.conv1.weight[:, 0:1, :, :] = \\\n",
    "                original_conv.weight.sum(dim=1, keepdim=True)\n",
    "    \n",
    "    def _configure_trainable_layers(self, trainable_layers):\n",
    "        \"\"\"Configure which layers are trainable\"\"\"\n",
    "        total_params = len(list(self.model.parameters()))\n",
    "        \n",
    "        if trainable_layers > 0:\n",
    "            print(f\"ResNet50: Unfreezing last {trainable_layers} layers \"\n",
    "                  f\"for fine-tuning, total {total_params} layers\")\n",
    "        else:\n",
    "            print(f\"ResNet50: Freezing all pretrained layers, \"\n",
    "                  f\"training classifier only\")\n",
    "        \n",
    "        trainable_count = 0\n",
    "        for i, param in enumerate(self.model.parameters()):\n",
    "            if i < total_params - trainable_layers:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "                trainable_count += 1\n",
    "        \n",
    "        print(f\"Total {trainable_count} layers unfrozen for training\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948b9057",
   "metadata": {},
   "source": [
    "# Training Utilities and Helper Functions\n",
    "\n",
    "This section implements essential training utilities that enhance training efficiency and prevent overfitting.\n",
    "\n",
    "**Key Utilities:**\n",
    "- **Early Stopping**: Monitors validation loss and stops training when performance plateaus\n",
    "- **Parameter Counting**: Calculates the number of trainable parameters in each model\n",
    "- **Mixed Precision Training**: Uses automatic mixed precision to speed up training and reduce memory usage\n",
    "- **Gradient Accumulation**: Simulates larger batch sizes on limited hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc899a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping utility to prevent overfitting\"\"\"\n",
    "    \n",
    "    def __init__(self, patience=3, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"Check if early stopping should be triggered\"\"\"\n",
    "        score = -val_loss\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count trainable parameters in model\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9582298c",
   "metadata": {},
   "source": [
    "# Training Engine\n",
    "\n",
    "The training engine orchestrates the complete training process with advanced optimization techniques.\n",
    "\n",
    "**Advanced Training Features:**\n",
    "- **Mixed Precision Training**: Uses FP16 to accelerate training while maintaining numerical stability\n",
    "- **Gradient Accumulation**: Enables effective larger batch sizes on memory-constrained hardware\n",
    "- **Learning Rate Scheduling**: Implements OneCycleLR for optimal convergence\n",
    "- **Progress Monitoring**: Real-time training progress with tqdm progress bars\n",
    "- **Automatic Checkpointing**: Saves best model weights based on validation performance\n",
    "\n",
    "**Training Loop Structure:**\n",
    "1. Forward pass with mixed precision\n",
    "2. Loss calculation and scaling\n",
    "3. Backward pass with gradient accumulation\n",
    "4. Parameter updates and learning rate scheduling\n",
    "5. Validation and early stopping checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dbd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \"\"\"Handle model training with mixed precision and gradient accumulation\"\"\"\n",
    "    \n",
    "    def __init__(self, model, train_loader, val_loader, model_name):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.model_name = model_name\n",
    "        self.device = Config.DEVICE\n",
    "        \n",
    "        # Move model to device\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # Initialize training components\n",
    "        self._setup_training_components()\n",
    "    \n",
    "    def _setup_training_components(self):\n",
    "        \"\"\"Setup optimizer, criterion, scheduler, and other training components\"\"\"\n",
    "        # Loss function\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Optimizer - AdamW with weight decay\n",
    "        self.optimizer = optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, self.model.parameters()),\n",
    "            lr=Config.LEARNING_RATE,\n",
    "            weight_decay=Config.WEIGHT_DECAY\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduler - OneCycleLR\n",
    "        self.scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "            self.optimizer,\n",
    "            max_lr=Config.MAX_LR,\n",
    "            steps_per_epoch=len(self.train_loader) // Config.ACCUMULATION_STEPS,\n",
    "            epochs=Config.NUM_EPOCHS\n",
    "        )\n",
    "        \n",
    "        # Mixed precision scaler\n",
    "        self.scaler = GradScaler()\n",
    "        \n",
    "        # Early stopping\n",
    "        self.early_stopping = EarlyStopping(\n",
    "            patience=Config.PATIENCE,\n",
    "            path=f'{Config.MODELS_DIR}/{self.model_name}_best.pth'\n",
    "        )\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        \"\"\"Train model for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        # Reset gradients\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Training loop with progress bar\n",
    "        pbar = tqdm(self.train_loader, desc=\"Training\")\n",
    "        for i, (inputs, labels) in enumerate(pbar):\n",
    "            inputs = inputs.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "            \n",
    "            # Mixed precision forward pass\n",
    "            with autocast():\n",
    "                outputs = self.model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = self.criterion(outputs, labels) / Config.ACCUMULATION_STEPS\n",
    "            \n",
    "            # Backward pass with gradient scaling\n",
    "            self.scaler.scale(loss).backward()\n",
    "            \n",
    "            # Gradient accumulation - update parameters every accumulation_steps\n",
    "            if (i + 1) % Config.ACCUMULATION_STEPS == 0:\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "                self.optimizer.zero_grad()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0) * Config.ACCUMULATION_STEPS\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({'batch_loss': loss.item() * Config.ACCUMULATION_STEPS})\n",
    "        \n",
    "        # Handle final batch if not divisible by accumulation_steps\n",
    "        if (i + 1) % Config.ACCUMULATION_STEPS != 0:\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            self.optimizer.zero_grad()\n",
    "        \n",
    "        epoch_loss = running_loss / len(self.train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(self.train_loader.dataset)\n",
    "        \n",
    "        return epoch_loss, epoch_acc.item()\n",
    "    \n",
    "    def validate_epoch(self):\n",
    "        \"\"\"Validate model for one epoch\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(self.val_loader, desc=\"Validation\"):\n",
    "                inputs = inputs.to(self.device, non_blocking=True)\n",
    "                labels = labels.to(self.device, non_blocking=True)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_val_loss = running_loss / len(self.val_loader.dataset)\n",
    "        epoch_val_acc = running_corrects.double() / len(self.val_loader.dataset)\n",
    "        \n",
    "        return epoch_val_loss, epoch_val_acc.item()\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Full training loop\"\"\"\n",
    "        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(Config.NUM_EPOCHS):\n",
    "            print(f'Epoch {epoch+1}/{Config.NUM_EPOCHS}')\n",
    "            print('-' * 10)\n",
    "            \n",
    "            # Training phase\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            print(f'Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}')\n",
    "            \n",
    "            # Validation phase\n",
    "            val_loss, val_acc = self.validate_epoch()\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                self.scheduler.step(val_loss)\n",
    "            else:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            # Early stopping check\n",
    "            self.early_stopping(val_loss, self.model)\n",
    "            if self.early_stopping.early_stop:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        print(f'Training completed in {training_time/60:.2f} minutes')\n",
    "        \n",
    "        # Load best model\n",
    "        self.model.load_state_dict(\n",
    "            torch.load(f'{Config.MODELS_DIR}/{self.model_name}_best.pth'))\n",
    "        \n",
    "        return history, training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a015649",
   "metadata": {},
   "source": [
    "# Model Evaluation and Testing\n",
    "\n",
    "This module provides comprehensive evaluation of trained models on the test dataset.\n",
    "\n",
    "**Evaluation Features:**\n",
    "- **Overall Accuracy**: Calculate model performance on the entire test set\n",
    "- **Per-class Accuracy**: Analyze performance for each Fashion-MNIST category\n",
    "- **Memory-efficient Testing**: Handle large test batches without memory overflow\n",
    "- **Detailed Performance Metrics**: Generate comprehensive performance reports\n",
    "\n",
    "**Why Per-class Analysis Matters:**\n",
    "Different clothing categories may have varying difficulty levels. Understanding per-class performance helps identify model strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9628c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    \"\"\"Handle model evaluation and metrics calculation\"\"\"\n",
    "    \n",
    "    def __init__(self, model, test_loader):\n",
    "        self.model = model\n",
    "        self.test_loader = test_loader\n",
    "        self.device = Config.DEVICE\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate model on test set\"\"\"\n",
    "        self.model.eval()\n",
    "        running_corrects = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(self.test_loader, desc=\"Testing\"):\n",
    "                inputs = inputs.to(self.device, non_blocking=True)\n",
    "                labels = labels.to(self.device, non_blocking=True)\n",
    "                \n",
    "                # Handle large batches to avoid memory issues\n",
    "                batch_size = inputs.size(0)\n",
    "                if batch_size > 64:\n",
    "                    outputs_list = []\n",
    "                    for i in range(0, batch_size, 64):\n",
    "                        end_idx = min(i + 64, batch_size)\n",
    "                        batch_outputs = self.model(inputs[i:end_idx])\n",
    "                        outputs_list.append(batch_outputs)\n",
    "                    outputs = torch.cat(outputs_list, dim=0)\n",
    "                else:\n",
    "                    outputs = self.model(inputs)\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        test_acc = running_corrects.double() / len(self.test_loader.dataset)\n",
    "        \n",
    "        # Calculate per-class accuracies\n",
    "        class_accuracies = []\n",
    "        for i in range(Config.NUM_CLASSES):\n",
    "            class_mask = np.array(all_labels) == i\n",
    "            if np.sum(class_mask) > 0:\n",
    "                class_acc = np.mean(np.array(all_preds)[class_mask] == i)\n",
    "                class_accuracies.append((CLASS_NAMES[i], class_acc))\n",
    "        \n",
    "        return test_acc.item(), class_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ee47a",
   "metadata": {},
   "source": [
    "# Results Visualization and Analysis\n",
    "\n",
    "Visualization is crucial for understanding model performance and comparing different approaches.\n",
    "\n",
    "**Visualization Components:**\n",
    "- **Training History Plots**: Show training/validation accuracy and loss curves over epochs\n",
    "- **Per-class Performance**: Bar charts showing accuracy for each clothing category\n",
    "- **Model Comparison**: Comprehensive comparison of different model configurations\n",
    "- **Performance Metrics**: Visual comparison of accuracy, training time, and parameter counts\n",
    "\n",
    "**Analysis Goals:**\n",
    "- Identify overfitting or underfitting patterns\n",
    "- Compare feature extraction vs fine-tuning effectiveness\n",
    "- Understand computational trade-offs between different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3168bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsVisualizer:\n",
    "    \"\"\"Handle visualization of training results and model comparisons\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_training_history(history, model_name, trainable_layers, test_acc):\n",
    "        \"\"\"Plot training history curves\"\"\"\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Plot accuracy curves\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "        plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "        plt.axhline(y=test_acc, color='r', linestyle='-', \n",
    "                   label=f'Test Accuracy: {test_acc:.4f}')\n",
    "        plt.title(f'{model_name} Model Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot loss curves\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history['train_loss'], label='Train Loss')\n",
    "        plt.plot(history['val_loss'], label='Validation Loss')\n",
    "        plt.title(f'{model_name} Model Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{Config.RESULTS_DIR}/{model_name}_trainable_{trainable_layers}_history.png')\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_class_accuracies(class_accuracies, model_name, trainable_layers, overall_acc):\n",
    "        \"\"\"Plot per-class accuracy bar chart\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        classes = [ca[0] for ca in class_accuracies]\n",
    "        accs = [ca[1] for ca in class_accuracies]\n",
    "        plt.bar(classes, accs)\n",
    "        plt.axhline(y=overall_acc, color='r', linestyle='-', \n",
    "                   label=f'Average: {overall_acc:.4f}')\n",
    "        plt.title(f'{model_name} (Trainable layers: {trainable_layers}) - Per-class Accuracy')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{Config.RESULTS_DIR}/{model_name}_trainable_{trainable_layers}_class_acc.png')\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_model_comparison(results):\n",
    "        \"\"\"Compare different model configurations\"\"\"\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        model_names = [f\"{r['model_name']} ({r['trainable_layers']})\" for r in results]\n",
    "        \n",
    "        # Compare test accuracies\n",
    "        plt.subplot(2, 2, 1)\n",
    "        accuracies = [r['test_accuracy'] for r in results]\n",
    "        bars = plt.bar(model_names, accuracies)\n",
    "        plt.title('Test Accuracy Comparison')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xticks(rotation=45)\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.4f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Compare training times\n",
    "        plt.subplot(2, 2, 2)\n",
    "        training_times = [r['training_time'] / 60 for r in results]\n",
    "        bars = plt.bar(model_names, training_times)\n",
    "        plt.title('Training Time Comparison (minutes)')\n",
    "        plt.ylabel('Time (minutes)')\n",
    "        plt.xticks(rotation=45)\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.1f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Compare trainable parameters\n",
    "        plt.subplot(2, 2, 3)\n",
    "        params = [r['trainable_params'] for r in results]\n",
    "        bars = plt.bar(model_names, params)\n",
    "        plt.title('Trainable Parameters Count')\n",
    "        plt.ylabel('Parameters')\n",
    "        plt.xticks(rotation=45)\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:,}', ha='center', va='bottom')\n",
    "        \n",
    "        # Compare epochs trained\n",
    "        plt.subplot(2, 2, 4)\n",
    "        epochs = [r['epochs'] for r in results]\n",
    "        bars = plt.bar(model_names, epochs)\n",
    "        plt.title('Training Epochs Comparison')\n",
    "        plt.ylabel('Epochs')\n",
    "        plt.xticks(rotation=45)\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{Config.RESULTS_DIR}/models_comparison.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92b5391",
   "metadata": {},
   "source": [
    "# Experiment Pipeline and Orchestration\n",
    "\n",
    "The experiment pipeline coordinates the entire transfer learning workflow from data preparation to results analysis.\n",
    "\n",
    "**Pipeline Structure:**\n",
    "1. **Data Setup**: Load and preprocess Fashion-MNIST dataset\n",
    "2. **Model Configuration**: Create different model variants (frozen vs fine-tuned)\n",
    "3. **Training Execution**: Train each model configuration\n",
    "4. **Performance Evaluation**: Test models and calculate metrics\n",
    "5. **Results Compilation**: Generate comprehensive comparison reports\n",
    "\n",
    "**Experimental Design:**\n",
    "- **MobileNetV2 Feature Extraction**: All pre-trained layers frozen\n",
    "- **MobileNetV2 Fine-tuning**: Last 5 layers unfrozen for adaptation\n",
    "- **ResNet50 Feature Extraction**: All pre-trained layers frozen  \n",
    "- **ResNet50 Fine-tuning**: Last 5 layers unfrozen for adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3511cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferLearningExperiment:\n",
    "    \"\"\"Main experiment pipeline for transfer learning\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_manager = None\n",
    "        self.train_loader = None\n",
    "        self.val_loader = None\n",
    "        self.test_loader = None\n",
    "        self.results = []\n",
    "    \n",
    "    def setup_data(self):\n",
    "        \"\"\"Setup data loading and preprocessing\"\"\"\n",
    "        self.data_manager = DatasetManager()\n",
    "        X_train, y_train, X_test, y_test = self.data_manager.load_and_prepare_data()\n",
    "        \n",
    "        # Visualize data samples\n",
    "        self.data_manager.visualize_samples(X_train, y_train)\n",
    "        \n",
    "        # Create data loaders\n",
    "        self.train_loader, self.val_loader, self.test_loader = \\\n",
    "            self.data_manager.create_data_loaders(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    def run_experiment(self, model_class, model_name, trainable_layers):\n",
    "        \"\"\"Run transfer learning experiment for a specific model configuration\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training {model_name} model (trainable layers: {trainable_layers})\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Create model\n",
    "        model = model_class(num_classes=Config.NUM_CLASSES, \n",
    "                           trainable_layers=trainable_layers)\n",
    "        \n",
    "        # Count trainable parameters\n",
    "        trainable_params = count_parameters(model)\n",
    "        print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        # Setup trainer\n",
    "        trainer = Trainer(model, self.train_loader, self.val_loader,\n",
    "                         f'{model_name}_trainable_{trainable_layers}')\n",
    "        \n",
    "        # Train model\n",
    "        history, training_time = trainer.train()\n",
    "        \n",
    "        # Evaluate model\n",
    "        evaluator = Evaluator(model, self.test_loader)\n",
    "        test_acc, class_accuracies = evaluator.evaluate()\n",
    "        \n",
    "        print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "        print(\"Per-class accuracies:\")\n",
    "        for class_name, acc in class_accuracies:\n",
    "            print(f\"  {class_name}: {acc:.4f}\")\n",
    "        \n",
    "        # Visualize results\n",
    "        ResultsVisualizer.plot_training_history(\n",
    "            history, model_name, trainable_layers, test_acc)\n",
    "        ResultsVisualizer.plot_class_accuracies(\n",
    "            class_accuracies, model_name, trainable_layers, test_acc)\n",
    "        \n",
    "        # Store results\n",
    "        results = {\n",
    "            'model_name': model_name,\n",
    "            'trainable_layers': trainable_layers,\n",
    "            'trainable_params': trainable_params,\n",
    "            'training_time': training_time,\n",
    "            'test_accuracy': test_acc,\n",
    "            'class_accuracies': class_accuracies,\n",
    "            'epochs': len(history['train_acc']),\n",
    "            'best_val_accuracy': max(history['val_acc']),\n",
    "            'best_val_loss': min(history['val_loss']),\n",
    "        }\n",
    "        \n",
    "        self.results.append(results)\n",
    "        return results\n",
    "    \n",
    "    def save_results(self):\n",
    "        \"\"\"Save experiment results to files\"\"\"\n",
    "        # Create comparison visualization\n",
    "        ResultsVisualizer.plot_model_comparison(self.results)\n",
    "        \n",
    "        # Save text summary\n",
    "        with open(f'{Config.RESULTS_DIR}/experiment_summary.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(\"Fashion-MNIST Transfer Learning Experiment Results\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            \n",
    "            for r in self.results:\n",
    "                f.write(f\"Model: {r['model_name']}\\n\")\n",
    "                f.write(f\"Trainable layers: {r['trainable_layers']}\\n\")\n",
    "                f.write(f\"Trainable parameters: {r['trainable_params']:,}\\n\")\n",
    "                f.write(f\"Test accuracy: {r['test_accuracy']:.4f}\\n\")\n",
    "                f.write(f\"Training time: {r['training_time'] / 60:.2f} minutes\\n\")\n",
    "                f.write(f\"Training epochs: {r['epochs']}\\n\")\n",
    "                f.write(f\"Best validation accuracy: {r['best_val_accuracy']:.4f}\\n\")\n",
    "                f.write(f\"Best validation loss: {r['best_val_loss']:.4f}\\n\")\n",
    "                f.write(\"\\nPer-class accuracies:\\n\")\n",
    "                for class_name, acc in r['class_accuracies']:\n",
    "                    f.write(f\"  {class_name}: {acc:.4f}\\n\")\n",
    "                f.write(\"-\" * 40 + \"\\n\\n\")\n",
    "        \n",
    "        # Save performance table\n",
    "        performance_table = \"# Model Performance Comparison\\n\\n\"\n",
    "        performance_table += \"| Model | Trainable Layers | Trainable Params | Test Accuracy | Training Time(min) | Epochs |\\n\"\n",
    "        performance_table += \"|-------|------------------|------------------|---------------|--------------------|---------|\\n\"\n",
    "        \n",
    "        for r in self.results:\n",
    "            performance_table += f\"| {r['model_name']} | {r['trainable_layers']} | {r['trainable_params']:,} | {r['test_accuracy']:.4f} | {r['training_time']/60:.2f} | {r['epochs']} |\\n\"\n",
    "        \n",
    "        with open(f'{Config.RESULTS_DIR}/performance_table.md', 'w', encoding='utf-8') as f:\n",
    "            f.write(performance_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0552a727",
   "metadata": {},
   "source": [
    "# Main Execution and Results\n",
    "\n",
    "This final section executes the complete experiment and generates comprehensive results.\n",
    "\n",
    "**Execution Flow:**\n",
    "1. Environment initialization\n",
    "2. Data preparation and visualization\n",
    "3. Sequential execution of all model configurations\n",
    "4. Performance comparison and analysis\n",
    "5. Results saving and report generation\n",
    "\n",
    "**Expected Outcomes:**\n",
    "- Performance comparison between feature extraction and fine-tuning\n",
    "- Analysis of MobileNetV2 vs ResNet50 effectiveness\n",
    "- Computational efficiency analysis (training time, parameters)\n",
    "- Insights into transfer learning best practices for Fashion-MNIST\n",
    "\n",
    "**Results Documentation:**\n",
    "- Numerical results saved in text format\n",
    "- Performance comparison tables in Markdown\n",
    "- Visual comparisons saved as PNG files\n",
    "- Model checkpoints for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12623e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the complete transfer learning experiment\"\"\"\n",
    "    # Setup environment\n",
    "    setup_environment()\n",
    "    \n",
    "    # Initialize experiment\n",
    "    experiment = TransferLearningExperiment()\n",
    "    \n",
    "    # Setup data\n",
    "    experiment.setup_data()\n",
    "    \n",
    "    print(\"\\nStarting transfer learning experiments...\\n\")\n",
    "    \n",
    "    # Run experiments for different model configurations\n",
    "    \n",
    "    # MobileNetV2 - Feature extraction (frozen pretrained layers)\n",
    "    experiment.run_experiment(MobileNetTransferLearning, 'MobileNetV2', 0)\n",
    "    \n",
    "    # MobileNetV2 - Fine-tuning (unfreeze last 5 layers)\n",
    "    experiment.run_experiment(MobileNetTransferLearning, 'MobileNetV2', 5)\n",
    "    \n",
    "    # ResNet50 - Feature extraction (frozen pretrained layers)\n",
    "    experiment.run_experiment(ResNet50TransferLearning, 'ResNet50', 0)\n",
    "    \n",
    "    # ResNet50 - Fine-tuning (unfreeze last 5 layers)\n",
    "    experiment.run_experiment(ResNet50TransferLearning, 'ResNet50', 5)\n",
    "    \n",
    "    # Save all results\n",
    "    experiment.save_results()\n",
    "    \n",
    "    print(\"\\nTransfer learning experiments completed. Results saved to 'results' directory.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb83ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
